{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install the api\n",
    "!pip install openai\n",
    "!pip install PyMuPDF pdf2image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up libraries\n",
    "import json\n",
    "import os\n",
    "import pymupdf\n",
    "from PIL import Image\n",
    "from pdf2image import convert_from_path\n",
    "import base64\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import shutil\n",
    "\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "#import output structure for auto-recognition\n",
    "from output_structure import tools "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess of the pdfs\n",
    "#combine them into one-pages and convert to image\n",
    "\n",
    "def combine_two_page (input_path):\n",
    "    input_pdf = pymupdf.open(input_path)\n",
    "    if len(input_pdf) != 2: \n",
    "        print (f\"Transfering {input_path}, not two-page\")\n",
    "        file_name = os.path.splitext(os.path.basename(input_path))[0]\n",
    "        output_path = os.path.join(output_dir,f\"{file_name}.pdf\")\n",
    "        image_path = os.path.join(output_dir,f\"{file_name}.jpg\")\n",
    "        input_pdf.save(output_path)\n",
    "\n",
    "        images = convert_from_path(output_path)\n",
    "        images[0].save(image_path)\n",
    "        return\n",
    "    #create new pdf\n",
    "    output_pdf = pymupdf.open()\n",
    "    new_page = output_pdf.new_page(width = 2*input_pdf[0].rect.width, height = input_pdf[0].rect.height)\n",
    "    left_rect = pymupdf.Rect(0, 0, input_pdf[0].rect.width, input_pdf[0].rect.height)\n",
    "    right_rect = pymupdf.Rect(input_pdf[0].rect.width, 0, 2*input_pdf[0].rect.width, input_pdf[0].rect.height)\n",
    "    new_page.show_pdf_page(left_rect, input_pdf, 0)\n",
    "    new_page.show_pdf_page(right_rect, input_pdf, 1)\n",
    "\n",
    "    file_name = os.path.splitext(os.path.basename(input_path))[0]\n",
    "    output_path = os.path.join(output_dir,f\"{file_name}.pdf\")\n",
    "    image_path = os.path.join(output_dir,f\"{file_name}.jpg\")\n",
    "    output_pdf.save(output_path)\n",
    "\n",
    "    images = convert_from_path(output_path)\n",
    "    images[0].save(image_path)\n",
    "    \n",
    "\n",
    "    print(f\"{file_name} combined and saved\")\n",
    "\n",
    "def  process_files_in_folder(folder_path, output_dir):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.endswith(\".pdf\"):\n",
    "            input_path = os.path.join(folder_path, file)\n",
    "            combine_two_page(input_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300063 combined and saved\n",
      "160049 combined and saved\n",
      "300060 combined and saved\n",
      "372024 combined and saved\n",
      "330015 combined and saved\n",
      "160088 combined and saved\n",
      "348019 combined and saved\n",
      "120127 combined and saved\n",
      "348009 combined and saved\n",
      "160073 combined and saved\n",
      "348021 combined and saved\n",
      "315092 combined and saved\n",
      "372035 combined and saved\n",
      "330004 combined and saved\n",
      "300058 combined and saved\n",
      "120132 combined and saved\n",
      "348036 combined and saved\n",
      "120246 combined and saved\n",
      "315053 combined and saved\n",
      "160065 combined and saved\n",
      "348078 combined and saved\n",
      "226010 combined and saved\n",
      "315021 combined and saved\n",
      "315035 combined and saved\n",
      "120022 combined and saved\n",
      "Transfering sample/361004.pdf, not two-page\n",
      "190086 combined and saved\n",
      "315020 combined and saved\n",
      "120037 combined and saved\n",
      "348051 combined and saved\n",
      "160015 combined and saved\n",
      "Transfering sample/359016.pdf, not two-page\n",
      "190090 combined and saved\n",
      "Transfering sample/372046.pdf, not two-page\n",
      "Transfering sample/361013.pdf, not two-page\n",
      "Transfering sample/349006.pdf, not two-page\n",
      "Transfering sample/359003.pdf, not two-page\n",
      "330089 combined and saved\n",
      "120187 combined and saved\n",
      "120024 combined and saved\n",
      "361003 combined and saved\n",
      "Transfering sample/361016.pdf, not two-page\n",
      "300011 combined and saved\n",
      "Transfering sample/359004.pdf, not two-page\n",
      "Transfering sample/359038.pdf, not two-page\n",
      "315030 combined and saved\n",
      "190097 combined and saved\n",
      "Transfering sample/349028.pdf, not two-page\n",
      "349014 combined and saved\n",
      "315019 combined and saved\n",
      "226000 combined and saved\n",
      "348071 combined and saved\n",
      "226025 combined and saved\n",
      "Transfering sample/349024.pdf, not two-page\n",
      "315029 combined and saved\n",
      "330083 combined and saved\n",
      "300020 combined and saved\n",
      "348070 combined and saved\n",
      "300036 combined and saved\n",
      "330042 combined and saved\n",
      "Transfering sample/349032.pdf, not two-page\n",
      "190073 combined and saved\n",
      "190067 combined and saved\n",
      "348098 combined and saved\n",
      "Transfering sample/349037.pdf, not two-page\n",
      "315013 combined and saved\n",
      "226036 combined and saved\n",
      "348060 combined and saved\n",
      "Transfering sample/361021.pdf, not two-page\n",
      "361035 combined and saved\n",
      "Transfering sample/349035.pdf, not two-page\n",
      "160040 combined and saved\n",
      "348006 combined and saved\n",
      "190012 combined and saved\n",
      "190006 combined and saved\n",
      "315088 combined and saved\n",
      "190007 combined and saved\n",
      "315076 combined and saved\n",
      "160082 combined and saved\n",
      "300057 combined and saved\n",
      "160069 combined and saved\n",
      "300043 combined and saved\n",
      "160055 combined and saved\n",
      "300069 combined and saved\n",
      "160080 combined and saved\n",
      "300096 combined and saved\n",
      "Transfering sample/349045.pdf, not two-page\n",
      "300040 combined and saved\n",
      "160085 combined and saved\n",
      "Transfering sample/349040.pdf, not two-page\n",
      "315071 combined and saved\n",
      "372015 combined and saved\n",
      "190028 combined and saved\n",
      "190000 combined and saved\n",
      "190029 combined and saved\n",
      "300045 combined and saved\n",
      "300051 combined and saved\n",
      "120111 combined and saved\n",
      "315099 combined and saved\n",
      "Transfering sample/361043.pdf, not two-page\n"
     ]
    }
   ],
   "source": [
    "folder_path = 'sample'\n",
    "output_dir = 'cards_in_image'# Temporary directory\n",
    "\n",
    "process_files_in_folder(folder_path, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode the images into base64 strings for model input\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, 'rb') as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(output_dir):\n",
    "    if file.endswith(\".jpg\"):\n",
    "            image = os.path.join(output_dir, file)\n",
    "            base64_image = encode_image(image)\n",
    "            file_name = os.path.splitext(os.path.basename(image))[0]\n",
    "            text_path = os.path.join(output_dir,f\"{file_name}.txt\")\n",
    "            with open(text_path, \"w\") as text:\n",
    "                 text.write(base64_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the api\n",
    "from openai import OpenAI\n",
    "api_key = 'YOUR_API_KEY' #YOUR_API_KEY\n",
    "client = OpenAI(api_key = api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create batch requests for recognition\n",
    "#check the variable doc for structural output details\n",
    "request_list = []\n",
    "\n",
    "def create_request(image_path,model=\"gpt-4o\", tools=tools):\n",
    "    custom_id = os.path.splitext(os.path.basename(image_path))[0]\n",
    "    with open(image_path, 'r') as image:\n",
    "        base64_image = image.read()\n",
    "    data = {\n",
    "                \"custom_id\": custom_id,\n",
    "                \"method\": \"POST\",\n",
    "                \"url\": \"/v1/chat/completions\",\n",
    "                \"body\": {\n",
    "                    \"model\": model,\n",
    "                    \"messages\": [\n",
    "                        {\n",
    "                            \"role\": \"user\", \n",
    "                            'content': [\n",
    "                                {\n",
    "                                    'type': 'text',\n",
    "                                    'text': 'extract all data from the patent card'\n",
    "                                },\n",
    "                                {\n",
    "                                    'type': 'image_url',\n",
    "                                    'image_url': {\n",
    "                                        'url':f'data:image/jpeg;base64,{base64_image}'\n",
    "                                    }\n",
    "                                }\n",
    "                            ]\n",
    "                        }\n",
    "                    ],\n",
    "                    \"max_tokens\": 1000,\n",
    "                    \"tools\": tools,\n",
    "                    \"tool_choice\": {\"type\": \"function\", \"function\": {\"name\": \"extract_patent_data\"}}\n",
    "                }\n",
    "            }\n",
    "    request_list.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cards_in_image/160015.txt\n",
      "cards_in_image/359016.txt\n",
      "cards_in_image/372046.txt\n",
      "cards_in_image/190090.txt\n",
      "cards_in_image/349006.txt\n",
      "cards_in_image/361013.txt\n",
      "cards_in_image/359003.txt\n",
      "cards_in_image/330089.txt\n",
      "cards_in_image/226010.txt\n",
      "cards_in_image/348078.txt\n",
      "cards_in_image/315021.txt\n",
      "cards_in_image/120022.txt\n",
      "cards_in_image/315035.txt\n",
      "cards_in_image/190086.txt\n",
      "cards_in_image/120037.txt\n",
      "cards_in_image/315020.txt\n",
      "cards_in_image/361004.txt\n",
      "cards_in_image/348051.txt\n",
      "cards_in_image/300011.txt\n",
      "cards_in_image/359004.txt\n",
      "cards_in_image/359038.txt\n",
      "cards_in_image/315030.txt\n",
      "cards_in_image/349028.txt\n",
      "cards_in_image/190097.txt\n",
      "cards_in_image/315019.txt\n",
      "cards_in_image/349014.txt\n",
      "cards_in_image/226000.txt\n",
      "cards_in_image/120187.txt\n",
      "cards_in_image/361003.txt\n",
      "cards_in_image/120024.txt\n",
      "cards_in_image/361016.txt\n",
      "cards_in_image/300060.txt\n",
      "cards_in_image/372024.txt\n",
      "cards_in_image/330015.txt\n",
      "cards_in_image/348019.txt\n",
      "cards_in_image/160088.txt\n",
      "cards_in_image/300063.txt\n",
      "cards_in_image/160049.txt\n",
      "cards_in_image/348036.txt\n",
      "cards_in_image/120246.txt\n",
      "cards_in_image/315053.txt\n",
      "cards_in_image/160065.txt\n",
      "cards_in_image/120127.txt\n",
      "cards_in_image/348009.txt\n",
      "cards_in_image/160073.txt\n",
      "cards_in_image/348021.txt\n",
      "cards_in_image/315092.txt\n",
      "cards_in_image/372035.txt\n",
      "cards_in_image/330004.txt\n",
      "cards_in_image/300058.txt\n",
      "cards_in_image/120132.txt\n",
      "cards_in_image/160080.txt\n",
      "cards_in_image/300096.txt\n",
      "cards_in_image/300069.txt\n",
      "cards_in_image/349045.txt\n",
      "cards_in_image/300040.txt\n",
      "cards_in_image/348006.txt\n",
      "cards_in_image/160040.txt\n",
      "cards_in_image/190012.txt\n",
      "cards_in_image/190006.txt\n",
      "cards_in_image/315088.txt\n",
      "cards_in_image/315076.txt\n",
      "cards_in_image/190007.txt\n",
      "cards_in_image/160069.txt\n",
      "cards_in_image/300057.txt\n",
      "cards_in_image/300043.txt\n",
      "cards_in_image/160055.txt\n",
      "cards_in_image/160082.txt\n",
      "cards_in_image/120111.txt\n",
      "cards_in_image/315099.txt\n",
      "cards_in_image/361043.txt\n",
      "cards_in_image/160085.txt\n",
      "cards_in_image/372015.txt\n",
      "cards_in_image/190028.txt\n",
      "cards_in_image/190000.txt\n",
      "cards_in_image/349040.txt\n",
      "cards_in_image/315071.txt\n",
      "cards_in_image/190029.txt\n",
      "cards_in_image/300045.txt\n",
      "cards_in_image/300051.txt\n",
      "cards_in_image/300036.txt\n",
      "cards_in_image/330042.txt\n",
      "cards_in_image/349032.txt\n",
      "cards_in_image/190073.txt\n",
      "cards_in_image/190067.txt\n",
      "cards_in_image/348098.txt\n",
      "cards_in_image/226025.txt\n",
      "cards_in_image/348071.txt\n",
      "cards_in_image/315029.txt\n",
      "cards_in_image/349024.txt\n",
      "cards_in_image/330083.txt\n",
      "cards_in_image/300020.txt\n",
      "cards_in_image/348070.txt\n",
      "cards_in_image/348060.txt\n",
      "cards_in_image/361021.txt\n",
      "cards_in_image/361035.txt\n",
      "cards_in_image/349035.txt\n",
      "cards_in_image/349037.txt\n",
      "cards_in_image/315013.txt\n",
      "cards_in_image/226036.txt\n"
     ]
    }
   ],
   "source": [
    "#create json file with requests\n",
    "image_dir = output_dir\n",
    "\n",
    "for file in os.listdir(image_dir):\n",
    "    if file.endswith(\".txt\"):\n",
    "        image_path = os.path.join(image_dir, file)\n",
    "        print(image_path)\n",
    "        create_request(image_path)\n",
    "\n",
    "shutil.rmtree(output_dir)\n",
    "\n",
    "jsonl_name = 'request_list.jsonl'\n",
    "with open(jsonl_name, 'w', encoding='utf-8') as jsonl_file:\n",
    "    for request in request_list:\n",
    "        jsonl_file.write(json.dumps(request,ensure_ascii=False) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#send request\n",
    "batch_input_file = client.files.create(\n",
    "    file = open(jsonl_name, 'rb'),\n",
    "    purpose='batch'\n",
    ")\n",
    "batch_input_file_id = batch_input_file.id\n",
    "batch = client.batches.create(\n",
    "    input_file_id=batch_input_file_id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    "    metadata={\n",
    "    \"description\": \"patent card extraction batch test on GPT-4o\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The task is validating now.\n"
     ]
    }
   ],
   "source": [
    "#check batch status each batch will be processed within 24 hours\n",
    "print(f\"The task is {batch.status} now.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patentnummer</th>\n",
       "      <th>klass</th>\n",
       "      <th>IPC</th>\n",
       "      <th>patenthavare_antal</th>\n",
       "      <th>patenthavare1</th>\n",
       "      <th>patenthavare1_adress</th>\n",
       "      <th>patenthavare1_stad</th>\n",
       "      <th>patenthavare1_land</th>\n",
       "      <th>patenthavare_typ</th>\n",
       "      <th>patenthavare_typ_av_skrivet</th>\n",
       "      <th>...</th>\n",
       "      <th>patenthavare3_land</th>\n",
       "      <th>uppfinnare4</th>\n",
       "      <th>uppfinnare5</th>\n",
       "      <th>tilläggspatentnummer</th>\n",
       "      <th>patentmeddelatden</th>\n",
       "      <th>patenttid_fr_2</th>\n",
       "      <th>patenttid_till_2</th>\n",
       "      <th>tidigare_patenthavare_adress</th>\n",
       "      <th>licensinnehavare</th>\n",
       "      <th>licensdatum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>160015</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>N.V. Philips’ Gloeilampfabrieken, Eindhoven</td>\n",
       "      <td>Eindhoven</td>\n",
       "      <td>Eindhoven</td>\n",
       "      <td>Nederländerna</td>\n",
       "      <td>company</td>\n",
       "      <td>typed</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>359016</td>\n",
       "      <td>A 01 g 23/08</td>\n",
       "      <td>A 01 g 23/08</td>\n",
       "      <td>1</td>\n",
       "      <td>Brundell och Jonsson AB</td>\n",
       "      <td>Gävle, SW</td>\n",
       "      <td>Gävle</td>\n",
       "      <td>SW</td>\n",
       "      <td>company</td>\n",
       "      <td>typed</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>372046</td>\n",
       "      <td>E 01 c 7/32</td>\n",
       "      <td>E 01 c 7/32</td>\n",
       "      <td>1</td>\n",
       "      <td>E.I. du de Nemours and Co.</td>\n",
       "      <td>Wilmington, Del.</td>\n",
       "      <td>Wilmington</td>\n",
       "      <td>US</td>\n",
       "      <td>company</td>\n",
       "      <td>typed</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>190090</td>\n",
       "      <td>56a</td>\n",
       "      <td>B66C1/62</td>\n",
       "      <td>1</td>\n",
       "      <td>Fabrikör Karl Erik Nilssen</td>\n",
       "      <td>Lidingö</td>\n",
       "      <td>Lidingö</td>\n",
       "      <td>Sverige</td>\n",
       "      <td>individual</td>\n",
       "      <td>typed</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>349006</td>\n",
       "      <td>B65g1/02</td>\n",
       "      <td>B65 g 1/02</td>\n",
       "      <td>1</td>\n",
       "      <td>Palmer-Shile Company</td>\n",
       "      <td>Detroit, Mich.</td>\n",
       "      <td>Detroit</td>\n",
       "      <td>USA</td>\n",
       "      <td>company</td>\n",
       "      <td>typed</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   patentnummer         klass           IPC patenthavare_antal  \\\n",
       "0        160015                                              1   \n",
       "1        359016  A 01 g 23/08  A 01 g 23/08                  1   \n",
       "2        372046   E 01 c 7/32   E 01 c 7/32                  1   \n",
       "3        190090           56a      B66C1/62                  1   \n",
       "4        349006      B65g1/02    B65 g 1/02                  1   \n",
       "\n",
       "                                 patenthavare1 patenthavare1_adress  \\\n",
       "0  N.V. Philips’ Gloeilampfabrieken, Eindhoven            Eindhoven   \n",
       "1                      Brundell och Jonsson AB            Gävle, SW   \n",
       "2                   E.I. du de Nemours and Co.     Wilmington, Del.   \n",
       "3                   Fabrikör Karl Erik Nilssen              Lidingö   \n",
       "4                         Palmer-Shile Company       Detroit, Mich.   \n",
       "\n",
       "  patenthavare1_stad patenthavare1_land patenthavare_typ  \\\n",
       "0          Eindhoven      Nederländerna          company   \n",
       "1              Gävle                 SW          company   \n",
       "2         Wilmington                 US          company   \n",
       "3            Lidingö            Sverige       individual   \n",
       "4            Detroit                USA          company   \n",
       "\n",
       "  patenthavare_typ_av_skrivet  ...  patenthavare3_land uppfinnare4  \\\n",
       "0                       typed  ...                 NaN         NaN   \n",
       "1                       typed  ...                 NaN         NaN   \n",
       "2                       typed  ...                 NaN         NaN   \n",
       "3                       typed  ...                 NaN         NaN   \n",
       "4                       typed  ...                 NaN         NaN   \n",
       "\n",
       "  uppfinnare5 tilläggspatentnummer patentmeddelatden patenttid_fr_2  \\\n",
       "0         NaN                  NaN               NaN            NaN   \n",
       "1         NaN                  NaN               NaN            NaN   \n",
       "2         NaN                  NaN               NaN            NaN   \n",
       "3         NaN                  NaN               NaN            NaN   \n",
       "4         NaN                  NaN               NaN            NaN   \n",
       "\n",
       "  patenttid_till_2 tidigare_patenthavare_adress licensinnehavare licensdatum  \n",
       "0              NaN                          NaN              NaN         NaN  \n",
       "1              NaN                          NaN              NaN         NaN  \n",
       "2              NaN                          NaN              NaN         NaN  \n",
       "3              NaN                          NaN              NaN         NaN  \n",
       "4              NaN                          NaN              NaN         NaN  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#when the task is completed, get the result\n",
    "#convert to dataframe\n",
    "output_file_id = client.batches.retrieve(batch.id).output_file_id\n",
    "file_response = client.files.content(output_file_id)\n",
    "\n",
    "text = pd.read_json(file_response, lines=True)\n",
    "response = pd.json_normalize(text['response'])\n",
    "tool_calls = pd.json_normalize(response['body.choices'].apply(lambda x: x[0]['message']['tool_calls'][0]))\n",
    "tool_calls['function.arguments'] = tool_calls['function.arguments'].apply(json.loads)\n",
    "rec_result = pd.json_normalize(tool_calls['function.arguments'])\n",
    "rec_result.head()\n",
    "\n",
    "rec_result['patentnummer'] = text['custom_id'] #replace the patent number with document name\n",
    "rec_result.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic post processing\n",
    "def output_clean(df):\n",
    "    df['patenthavare1_stad'] = df.apply(\n",
    "        lambda row: row['patenthavare1'].split(',')[1].strip() if row['patenthavare1_stad'] == '' and ',' in row['patenthavare1'] else row['patenthavare1_stad'],\n",
    "        axis=1\n",
    "    ) #try to fill in the city manually if it is not recognized\n",
    "    df['patenthavare1'] = df['patenthavare1'].str.split(',').str[0] #separate the location information\n",
    "    \n",
    "    #to flag the potential wrong expiration date\n",
    "    df['utgångsår'] = pd.to_numeric(df['utgångsår'], errors='coerce')\n",
    "    df['sista_aviserat_år'] = pd.to_numeric(df['sista_aviserat_år'], errors='coerce')\n",
    "   \n",
    "    df['potential_wrong_expiration_date'] = df.apply(\n",
    "        lambda row: 1 if pd.notnull(row['utgångsår']) and  pd.notnull(row['sista_aviserat_år'])\n",
    "         and int(row['utgångsår']) - int(row['sista_aviserat_år']) >1 and row['utgångsskäl'] == 'Lack of payment of fees' else 0,\n",
    "        axis = 1\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the output as csv\n",
    "rec_result = output_clean(rec_result)\n",
    "rec_result.to_csv(\"rec_result_with_flag.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cardrec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
